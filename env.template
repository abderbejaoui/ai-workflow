# Environment Configuration Template
# Copy this to .env and fill in your actual values

# LLM Configuration
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Supervisor uses lightweight model for speed
SUPERVISOR_MODEL=gpt-4o-mini
SUPERVISOR_TEMPERATURE=0.0

# Main LLM for responses
MAIN_MODEL=gpt-4o
MAIN_TEMPERATURE=0.7

# Databricks Configuration
DATABRICKS_SERVER_HOSTNAME=your_server.cloud.databricks.com
DATABRICKS_HTTP_PATH=/sql/1.0/warehouses/your_warehouse_id
DATABRICKS_ACCESS_TOKEN=your_databricks_token

# Performance Settings
DATABRICKS_QUERY_TIMEOUT=2
MAX_RESULT_ROWS=1000
CONVERSATION_HISTORY_LIMIT=5

# Confidence Thresholds
DATABRICKS_CONFIDENCE_THRESHOLD=0.75

# Logging Configuration
LOG_LEVEL=INFO                    # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_TO_FILE=true                  # Enable file logging
LOG_FILE=logs/ai_workflow.log     # Log file path
LOG_STRUCTURED=false              # Use JSON structured logging

